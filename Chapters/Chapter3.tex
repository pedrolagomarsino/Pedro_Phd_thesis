% Chapter 3

\chapter{Materials and Methods} % Main chapter title

\label{Chapter3} % For referencing the chapter elsewhere, use \ref{Chapter3} 

% =========================================================== %
%          Subsection: Experimental procedures                %
% =========================================================== %
\section{Experimental procedures}
\label{chap3:sec:1:exp_proc}
\subsection{Animals}
All experiments involving animals were approved by the National Council on Animal Care of the Italian Ministry of Health and carried out in accordance with the guidelines established by the European Communities Council Directive authorization (61/2019-PR). 
From postnatal days 30, animals were separated from the original cage and group housed (2â€“5 per cage) in a 12-hours light-dark cycle with \textit{ad libitum} access to food and water. 
Only animals older than 10 weeks underwent experimental procedures. 

\subsection{AAV injection and surgery for chronic hippocampal imaging}
\label{chap3:sec:1:subsec2:AAV_injection}
Neuronal-specific GCaMP6f expression was obtained using AAV1.CamKII.GCaMP6f.WPRE.SV40 (Addgene viral prep \# 100834-AAV1).
Astrocytic-specific DREADD expression was obtained using AAV-GFAP-hM3D(Gq)-mCherry (Addgene viral prep \# 50478-AAV5)

Male C57Bl6/j mice were placed into a stereotaxic apparatus (Stoelting Co, Wood Dale, IL), maintained on a warm platform at $37^{\circ}$C and anesthetized with 2\% isoflurane/0.8\% oxygen. 
Before surgery, a bolus of Dexamethasone (4 mg/kg, Dexadreson, MSD Animal Health, Milan, IT) was provided with an intramuscular injection. 
A small circular craniotomy (diameter, 0.5 mm) was drilled on the right hemisphere (1.75 mm posterior, 1.35 mm lateral to bregma) after scalp incision. 
A micropipette loaded with AAV was then lowered into the CA1 region of the hippocampus (1.40 mm deep to bregma). 
800 nl of solution containing the two AAVs for GCaMP6f (dilution, 1:5) and DREADD (dilution, 1:8) was injected at 100 nL/min using a hydraulic injection apparatus driven by a syringe pump (UltraMicroPump, WPI, Sarasota, FL). 
After viral injection, a stainless-steel screw was positioned on the skull of the left hemisphere and a chronic hippocampal window was implanted following (\cite{dombeck2010}, \cite{sheffield2015}). 
A 3 mm craniotomy centered at coordinates 2.00 mm posterior and 1.80 mm lateral to bregma was opened using a drill and the dura was removed using fine forceps. 
A blunt needle coupled to a vacuum pump was used to carefully aspirate the cortical tissue overlaying the hippocampus. 
The exposed tissue was continuously irrigated during aspiration with HEPES-buffered artificial cerebrospinal fluid (ACSF). 
Aspiration was interrupted when the thin fibers of the external capsule were visible. 
A cylindrical cannula-based optical window was then positioned at the craniotomy touching the external capsule. 
A thin layer of silicone elastomer (Kwik-Sil, World Precision Instruments, Sarasota, FL) was used to fill and isolate the space between the steel surface of the optical window and the brain tissue. 
Epoxy glue was used to attach a custom stainless-steel headplate to the skull.
Black dental cement was used to secure each component in place.
An intraperitoneal bolus of antibiotic (BAYTRIL, Bayer, DE) was administrated to animals after surgery.

Optical windows consisted of stainless-steel cannula segments with thin walls (outer diameter, 3 mm; inner diameter, 2.77 mm; height, 1.50 - 1.60 mm). 
At one end of the cannula a 3.00 mm diameter round coverslip was attached by means of UV curable optical epoxy (Norland optical adhesive 63, Norland, Cranbury, NJ). 
Bonding residues and Edges were smoothed with a diamond coated cutter.

\subsection{Two-photon imaging}
Two-photon calcium imaging was performed using an Ultima Investigator or an Ultima II scanheads (Bruker Corporation, Milan, IT) equipped with raster scanning galvanometers (mirror dimension, 6 mm or 3 mm) a 16x/0.8 NA objective (Nikon, Milan, IT), and multi-alkali photomultiplier tubes. 
For GCaMP6f imaging, the excitation pulsed laser sources were either a Chameleon Ultra or a Chameleon Ultra II, both tuned at 920 nm (repetition rate, 80 MHz; Coherent, Milan, IT).
Before every experimental session, each FOV was imaged at 740 nm to confirm the expression of DREADD-mCherry construct. 
Laser beams intensity was adjusted using Pockel cells (Conoptics Inc, Danbury, CT).
Imaging average power at the objective focus was $\sim 80-110 mW$. 
Fluorescence emission was collected using multi-alkali PMT detectors downstream of appropriate emission filters (525/70 nm for GCaMP6f, 595/50 nm for red reporter fluorophores). 
Detector signals were digitalized at 12 bits. 
Imaging was conducted in raster scanning mode at $\sim 3$ Hz using 5x optical zooming factor. 
Images contained 256 pixels x 256 pixels field-of-view (FOV). The pixel dwell-time was set at $4 \mu s$. The pixel size was $0.634 \mu m$ for the Investigator scanhead and $0.509 \mu m$ for the Ultima II scanhead.
For recordings in which we imaged the same FOV over days (longitudinal recordings), imaging was performed at $9.972$ Hz with 3x optical zoom factor.
Images contained 128 x 128 pixels, dwell-time was set at $2.8 \mu s$ and pixel size was $2.144 \mu m$.
\subsection{Longitudinal recordings}
\label{chap3:sec:1:subsec4:long_recordings}
To perform longitudinal recordings, we implemented a protocol to precisely image the same FOV over different days based on a series of acquired coordinates and images. 
More specifically, we first head fixed using a \textit{Luigs\&Neumann} apparatus, which allowed movements according to 5 coordinates.
These coordinates were chosen to minimize the tilting of the cannula relative to the wheel, annotated, and saved for the following sessions.
Moreover, a laser pointer was attached close to the mouse head and the position of the laser spot projected $\sim$ 40 cm away from the mouse was also annotated and used as an additional spatial reference.
Several two-photon images at high resolution (1024x1024) of the FOV were acquired.
Images were taken at the level of the fibers of the corpus callosum where the Z axis was zeroed and at the level of the hippocapal stratum pyramidale without zoom and at 3x zoom.
Functional imaging was then performed in the first session of a longitudinal imaging experiment.
During subsequent imaging sessions, the mouse was positioned according to the previously annotated coordinates and the projection of the laser pointer was aligned with the reference position. A wide field image of the FOV was acquired with a basler camera both with a 5x objective and the 16x objective. 
This images were used to finely re-positioning the FOV, mostly based on the position of the vasculature, which provided clear and stable landmarks.
Fine and final re-positioning was obtained using the median projection of short t-series.

\subsection{Animal habituation}
After 7-14 days from surgery, animals were subjected to water restriction and delivered 1 ml of water per day.
Mouse weight was monitored on a daily basis to  maintain the animal's weight between 80 \% and 90 \% of the \textit{ad libitum} weight throughout the complete duration of the experiments. 
A minimum of two sessions of \enquote{handling} (i.e. mouse habituation to the experimenter) was performed two days after water scheduling. 
In subsequent training sessions, mice were then habituated to the VR setup. 
This was achieved by head-restraining the animals for progressively longer periods (up to 1 hour) in multiple training sessions (one per day). 
In each training/habituation session, mice were exposed to the noise generated by the two-photon imaging setup (galvanometer scanning noise, shutter noise), even when no imaging was performed.
Training in the setup was performed until animals routinely ran along the linear track. 
On experimental days, mice were head-tethered, and VR session begun after a suitable FOV was identified. 
3 to 6 t-series (750 frames/series, $\sim 250 s$), interleaved by 5 minutes breaks, were acquired during $\sim$ 1 hour virtual navigation session. 
At the end of each imaging session, animals were returned to their home cage.
% =========================================================== %
%    Subsection: Data acquisition and pre-processing          %
% =========================================================== %
\section{Data acquisition and pre-processing}
\label{chap3:sec:2:preproc}
% In this work we dealt with diverse and complex datasets, of different types and structures and therefore, that require different pre-processing pipelines. 
% Here the details for each case.
% \subsection{Inscopix 1-photon imaging}
% \label{chap3:sec:2:subsec1:inscopix-pre-proc}
% The Inscopix software acquires imaging data from miniscopes in freely moving animals. The imaging data is then exported as \textit{.isxd} files containing the images and the metadata. 
% Such files can only be read and treated with Inscopix own proprietary software (\textbf{poner el link}), the following pre-processing was performed using such software. 

% All five imaging series corresponding to the same animal in the same day were first concatenated, cropped and downsampled in space and time. 
% Temporal downsampling works by averaging $n$ adjacent frames, where $n$ is the temporal downsample factor. 
% The moving average stride is equal to the temporal downsample factor, which results in non-overlapping groups of frames to be averaged. 
% This is equal to binning the frame data in time (in bins defined by the temporal downsample factor) and the subsequent averaging of each bin. 
% The resulting number of frames equals the original number of frames divided by the temporal downsample factor, rounded down. 
% Spatial downsampling works similarly, except that the spatial bins are non-overlapping sub-images of the original frames.
% For all recordings we used a temporal and spatial downsample factor of 2 and 4 respectively.  
% Both downsampling stages were used to be able to realistically mange data size and computation time. \\
% To remove defective pixels a 3x3 median filter was applied to the movies, and early frames which were dark or dim were trimmed.\\  
% A spatial filter algorithm was then applied to each movie to remove low and high spatial frequency content. In practice the algorithm bandpass the images by convolving each frame with a gaussian kernel and subtracting a smoothed version of the frame from a less smoothed version of the frame.
% Parameters of the bandpass filter were set to \textbf{Low cut-off} $ = 0.005 \ {pixel}^{-1}$ and a  \textbf{High cut-off} $ = 0.5 \ {pixel}^{-1}$. \\
% Then each concatenated recording was motion corrected to compensate for unwanted motion of the brain relative to the skull.
% For each frame of the movie, motion correction estimates a translation that minimizes the difference between the transformed frame and the reference frame, using an image registration method described in \textit{REF [Thevenaz1998]}. \\
% Then the fluorescence in each pixel was normalize by the average fluorescence across frames to obtain the $\Delta F/F$, so that it represents a deviation or change from a baseline.  
% =========================================================== %
%            Subsection: Animal tracking                      %
% =========================================================== %
% \section{Animal tracking}
% \label{chap3:sec:3:tracking}

\subsection{Virtual reality Linear track}
\label{chap3:sec:3:subsec1:linear-track-tracking}
A custom virtual reality (VR) setup was design and implemented using Blender, an open source 3D creation suite (blender.org, version 2.78c). 
VR was rendered with Blender Game Engine and displayed at a video rate of 60 Hz. 
The VR environment was a linear corridor with lateral walls depicting three different white textures (vertical lines, mesh, and circles) on a black background. 
Extremes of the corridor were represented as green walls labeled with a black cross.
The corridor was 180 cm long and 9 cm wide. 
The animal was represented in the VR environment with a spherical avatar of radius 2 cm.
To simulate touch-interactions with the environment, a touch sensor represented with a rectangular cuboid of dimensions ($x = 5, y = 1, z = 1 cm$) was included, protruding the animals avatar parallel to the corridor floor.
Composite tiling of five thin-bezel led screens were used to project the avatars point of view in the VR environment ($220^{\circ}$ horizontal, $80^{\circ}$ vertical). 
Mice could virtually navigate the environment by running on a custom 3D printed wheel (radius 8 cm, width 9 cm). 
Motion was captured with an optical rotary encoder (Avago AEDB-9140-A14, Broadcom Inc., San Jose, CA), whose signal was converted into a serial mouse input by a single board microcontroller (Arduino Uno R3, Arduino, Ivrea, Italy). 
Physical motion performed by the animal and measured by input devices was then mapped with a 1:1 correspondence to the virtual environment. 
To motivate mice to explore and navigate the virtual corridor, a $\sim 4 \mu l$ water reward was delivered when the mouse reached the position $115 cm$ along the VR corridor. 
Rewards were delivered through a custom steel lick-port controlled by a solenoid valve (00431960, Christian BÃ¼rkert GmbH \& Co., Ingelfingen, DE) and licks were monitored using a capacitive sensor (MTCH102, Microchip Technology Inc., Chandler, AZ). 
Upon reaching the end of the corridor, animals were teleported back to the beginning of the track and a new trial was started.
If instead the mouse failed to reach the end of the track within 120 s, the trial was automatically terminated and the animal teleported to the beginning of the track. 
After trial termination, either by reaching the end of the track or in terminated runs,  a timeout interval of $5 s$ was applied before a new trial started.
VR rendering and two-photon imaging acquisition were synchronized using the command signal of the x galvanometer.

\subsection{Motion correction}
2-photon microscopy experiments produced t-series consisting of sequential \textit{.tiff} images. 
All images corresponding to a t-series were first concatenated to produce an \textit{.avi} video with no compression.
Motion correction was performed using the \textit{NoRMCorre} algorithm [\cite{pnevmatikakis2017}], that corrects non-rigid motion artifacts by estimating motion vectors with subpixel resolution over a set of overlapping patches within the FOV. 
These estimates were used to infer a smooth motion field within the FOV for each frame. 
The inferred motion fields were applied to the original data frames.
For \textit{NoRMCorre} correction  the following characteristics was used: patch size $(48,48)$ pixels, maximum overlap of $(24,24)$ pixels between patches, max rigid shift of $(6,6)$ pixels, and a maximum relative shift of each patch with respect to rigid shifts of 3 pixels.  

Motion correction was applied in two steps, first each t-series was motion corrected individually.
Then, all t-series from the same day and same animal were concatenated and motion corrected again.
For longitudinal recordings a third step of motion correction was included.
After each day was motion corrected, all days belonging to the same FOV were concatenated and motion correction was performed again to maximize the correspondence across days. 
Motion corrected recordings were finally split again and analyzed separately for each day.
% \subsection{2-D arena}
% \label{chap3:sec:3:subsec2:2d-arena-tracking}
% In the random foraging and open field experiments in the 2-dimensional arena animals were free to move and explore a $45 cm x 45 cm$ square box. The box was filmed using a \textbf{CAMARA MODEL} placed at \textbf{DISTANCE} meters from the floor. \\
% Animal position was estimated from these videos using the software package \textbf{DeepLabCut} (DLC) \textbf{Link to the githubpage}.\\
% DLC is a free software 000000000000000000000000000000000000000
% =========================================================== %
%          Subsection: Video Segmentation                     %
% =========================================================== %
\section{Video Segmentation}
\label{chap3:sec:4:segmentation}
To infer neuronal activity, imaging data were first segmented using the customized algorithm CITE-on (Cell Identification and Trace Extraction online). 
CITE-on was a convolutional neural network-based algorithm for automatic online cell identification, segmentation, identity tracking, and trace extraction in two-photon calcium imaging data. 
The off-line cell identification suit was used on the median projection of the full length concatenated recordings.
By using the median projection of the full motion corrected concatenated recordings, the amount of detected neurons was maximized.
CITE-on implemented an image detector based on the publicly available convolutional neural network (CNN) RetinaNet [\cite{lin2020}].
The output of the CNN image detection was a set of boxes tightly surrounding each detected cell soma, from here on called \textit{bounding boxes}.
Coordinates and identity of the bounding boxes were saved and used in the following steps. 
Because the motion correction was performed across t-series and the median projection was calculated on the full-length recording, the coordinates and identities of the bounding boxes were preserved across frames and t-series and did not require any adjustment or tracking across frames. 
CITE-on required an upscaling factor that depended on the ratio between the FOV surface and the average surface of the neuronal somata. 
This parameter was optimized to obtain the tightest fit of bounding boxes to cell somatas. in all recordings presented in this work this parameter was set to $0.7$.  

\section{Longitudinal tracking}
\label{chap3:sec:5:long_tracking}
In longitudinal recordings, video segmentation was applied separately for each day, and cell identities were matched \textit{a posteriori}. 
To compare sets of bounding boxes, we computed the intersection over union ($iou$) for all pairs of boxes. 
Pairs with $iou>0.5$ were considered matching identities, if a box from one set satisfied this condition with more than 1 box from the other set, then the pair with the biggest $iou$ was considered as matching identities. 
Matching procedure was applied between the set of bounding boxes from first day of recording and the second and then between the first and third day of recordings.
The intersection between both matching sets were the cells that we considered as \textbf{tracked}.
All cells that had not a matching identity between first and second day and/or first and third day were considered as \textbf{non tracked} cells. 
% =========================================================== %
%               Subsection: Trace extraction                  %
% =========================================================== %
\section{Trace extraction}
\label{chap3:sec:5:trace_extraction}
After cell identification, the following step to infere neuronal activity consisted in extracting functional calcium traces from identified cells. 
This was achieved using the algorithm CaImAn, a popular state-of-the-art method based on Constrained Non-Negative Matrix Factorization (CNMF) [\cite{giovannucci2019}].
We used the bounding boxes generated offline by CITE-On to build binary masks that were used as seeds to initialize the seeded-CNMF algorithm.
Seeded-CNMF calculated first the temporal background component of the recording using pixels that were not included in any mask. This background component was later subtracted from each neuronal factor. 
It represented the background noise shared across all signals, including the neuropil activity.
The seeded-CNMF algorithm then estimated temporal components and spatial footprints, constrained to be non-zero only at the location where the binary masks were positioned.
Parameters for seeded-CNMF were explored and tuned manually. Specifically: the number of global background components was 2; no merging was performed; the number of components per patch was $= 4$ ; the expected half size of neurons in pixels was $= (7,7)$; no spatial or temporal subsampling was performed.
Finally, for each component the $\Delta F/F_0$ was computed with the CaImAn \textbf{detrend\_df\_f} function (see \cite{giovannucci2019}), using the $50^{th}$ quantile as baseline and a 2000 frames running window to compute quantiles.  

The combination of off-line CITE-on and CaImAn presented several advantages for the analysis of our dataset.
Off-line CITE-on localized putative neurons considering only anatomical aspect, regardless of their activity profile.
CaImAn then refined the segmentation for each binding box and provided denoised calcium traces. 
Neither deconvolution nor spike inference were used. 
% =========================================================== %
%          Subsection: Event detection                        %
% =========================================================== %
\section{Event detection}
\label{chap3:sec:6:event_det}
For each component obtained after trace extraction, statistically significant calcium events were detected on the $\Delta F/F_0$ traces with a modified implementation of the algorithm described in [\cite{dombeck2007}]. 
Briefly, the standard deviation $\sigma_1$ of the signal was computed and points with absolute value larger than $\sigma_1$ were removed from the trace. 
This procedure automatically excluded large transients.
Then, the standard deviation, $\sigma_2$, of the resulting trace was computed. 
Fluorescence transients were identified as events that:
%\renewcommand{\labelenumi}{\roman{enumi}}
\begin{enumerate}[label=\roman*)]
    \item were bigger in absolute value than $3\ \sigma_2$ 
    \item didn't return within $2\ \sigma_2$ before 0.5 s [\cite{dombeck2007}].
\end{enumerate}
These criteria were selected to obtain a false discovery rate $< 5\%$.
False discovery rate was defined as: 
\begin{equation}
    FDR = \frac{N_{E_n}}{N_{E_p}+N_{E_n}}
\end{equation}
where $N_{E_p}$ and $N_{E_n}$ were the numbers of identified positive and negative deflections of the $\Delta F/F_0$ trace, respectively. 
An \textbf{event trace} could be obtained by setting all fluorescent values from the $\Delta F/F_0$ trace that did not belong to a positive event to 0. 
We called such trace the \textit{event trace}.

% =========================================================== %
%          Subsection: Place Cell detection                   %
% =========================================================== %
\section{Place Cell detection}
\label{chap3:sec:7:pc_det}
\subsection{Response profiles and response fields}
\label{chap3:sec:7:subsec1:PF_and_response_profiles}
Only instants in which the animal was running at a speed $> 1 cm/s$ were considered for the analysis. 
% Analysis was performed in trials matching the following criteria: 
% i) mouse running speed $> 1 cm/s$;  I THINK THIS IS THE ONLY CONDITION 
% ii) running bout $> 20 cm$; 
% iii) running bouts separated by no running for $< 15$ s were considered as the same bout.
% The length of the virtual corridor was binned (number of spatial bins, 80; bin width, 2.25 cm). 
The virtual corridor was binned using 81 equally spaced bins and the occupancy map was calculated for each animal. 
The occupancy map represented the total amount of time spent in each spatial bin. 
The activity map was then computed for each ROI as the average fluorescence value in each spatial bin. 
The sum of both the activity and the occupancy maps were normalized to 1 and convolved with a Gaussian kernel with a width of 3 spatial bins. 
We defined the response profile of a ROI (RP) as the ratio of its activity map over the occupancy map. 
For each RP, we defined and computed a response field (RF) as follows: 
\begin{enumerate}[label=\roman*)]
    \item we identified all local maxima greater than the $25^{th}$ percentile of the response profile values  $C = (c_0, c_1, ... , c_n)$
    \item we fitted the response profiles as the sum of $n$ parametrized Gaussian functions, with means equal to the elements of $C$.
    The amplitude, $a_i$, and standard deviations, $\sigma_i$, were constrained to take values $ 0 \leq a \leq 1 $ and $0 \leq \sigma \leq 90 cm$, respectively. 
    The fitting was performed by solving a non-linear least squares problem using the function \textit{curve\_fit}, from scipy, \url{www.scipy.org}).
    Formally,
    \begin{equation}
        RP \cong \sum_{c_i\in C} a_i\exp{\frac{-(x-c_i)^2}{2\sigma_i^2}}
    \end{equation}
    With the following constrains: 
    \begin{equation}
        \begin{cases}
            0\leq c_i \leq 180\ \forall\ c_i \in C \\
                0\leq a_i \leq 1\ \forall\ a_i \in A \\
                    0\leq \sigma_i \leq 90\ \forall\ \sigma_i \in S
        \end{cases}
    \end{equation}
    \item the RF was defined as the fitted gaussian with the highest amplitude, and its width as $2\ \sigma_i$
    \begin{equation}
        RF = a_i\exp{\frac{-(x-c_i)^2}{2\sigma_i^2}} \quad \text{with} \quad  i=argmax(A)
    \end{equation}
\end{enumerate}

\subsection{Place cells analysis}
\label{chap3:sec:7:subsec2:pc_analysis}
Only periods in which the animal running speed was $> 1 cm/s$ were used to analyze the spatial modulation of neuronal cell activity. 
We defined spatial modulation based on information theory (see section \ref{chap1:sec:3:subsec1:information_theory}, \cite{shannon1948}, \cite{quirogapanzeri2013}). 
We computed the mutual information between position in the linear track $P$ and the neuronal calcium event trace $F$ using equation \ref{eqn:mutualinfo1}:
\begin{equation}
\label{eqn:mutualinfoPF}
    I(F\ :\ P) = H(F)+H(P)-H(F , P)
\end{equation}
Where $H$ is the Shannon entropy as defined in equation \ref{eqn:entropy}:
\begin{equation}
    H(X)= -\sum_{x\in X}p(x)\ log_2(p(x))
\end{equation}
Here $X = (x_0, x_1, ... , x_n)$ represented all possible discrete values of either $F$ or $P$.
And $H(F,P)$ is the joint entropy as defined in equation \ref{eqn:jointentropy}.

To answer the question of whether a cell carried \textbf{significant amount of information} in its calcium activity, we compared the mutual information of that cell with a surrogate distribution of mutual information values. 
These values were obtained by calculating the mutual information of surrogate traces that were cyclic permutations of the temporally inverted original trace.
The permutations were done shifting the traces by a random amount of time bigger than the $5\%$ of the length of the trace and smaller than the $95\%$.
Importantly, this surrogate method preserved many features of the trace, such as auto-correlation, temporal structure, mean value, etc.., but destroyed the temporal relationship between neuronal activity and position.  
This procedure was perform 1000 times for each ROI to build the null distribution of mutual information values.
A cell whose mutual information value was higher than the $95^{th}$ percentile of the null distribution was considered a \textbf{place cell}. 

\subsection{Bias correction and parameter selection}
\label{chap3:sec:7:subsec3:bias_correction}
As mentioned in the introduction (see section \ref{chap1:sec:3:subsec1:information_theory}), using an empirical probability distribution as approximation of the true underlying probability distribution produced biased values of mutual information (MI). 
The contribution of the bias to the MI value strongly depended on how we binned the variables; higher number of bins better described the data but produces bins with less counts and therefore worst estimates of their probabilities. 
To account for this bias, we first computed the parameter: 
\begin{equation}
    NsR = log_2(\frac{N_s}{R})
\end{equation}
with $N_s$ being the average number of counts in position bins, and $R$ the number of stimulus bins (that is the amount of steps in which we binned calcium intensities).
$NsR$ gave a quantitative measure of how well we could estimate the probability distributions: the larger it is, the smaller the bias. 
We considered $NsR=3$ as a conservative threshold, above which the description quality was good.
For each recording, we calculated $NsR$ for different number of intensity bins ($r_{bins} = [2,3,4,5,8,10,20]$) and position bins ($s_{bins} = [4,8,12,16,20,24,40,60,80,100,160]$).
We then calculated the contribution of the bias for each ROI as the mean of the null distribution, using the surrogate distribution described in the previous section. 
The \textbf{unbiased value of MI} was thus defined as the MI value calculated as in equation \ref{eqn:mutualinfoPF} minus the bias:
\begin{equation}
    \label{eqn:unbias_mutualinfo}
    MI_{unbiased}=I(F\ :\ P) - \langle I(F_{s}\ :\ P)\rangle_{surrogates}
\end{equation}
We calculated the average unbiased MI value across ROIs for each combination of numbers of intensity and position bins and their standard deviation. We then split these averages in place cells and non-place cells. 
By doing so, we studied the contribution of the bias as a function of the binning of the variables.
Higher contribution of the bias decreased the value of the unbiased MI.
At the same time, we expected that if the bias was correctly subtracted, the non place cells had unbiased MI values close to zero, while place cells had positive MI values. 
We therefore selected the appropriate combination of space and intensity binning as that with the highest number of bins which had a $NsR>3$ and which maximized the unbiased MI. 
This procedure allowed comparison of MI values across recordings, experimental conditions, and ROIs. 
We performed all the aforementioned steps for two binning procedures for space: $i)$ uniform width bins; $ii)$ uniform count bins yielding a uniform distribution of space occupancy.
This last computational step served as a control for the consistency of the unbiased MI values across binning procedures. 
% =========================================================== %
%          Subsection: Statistical testing                    %
% =========================================================== %
\section{Statistical testing}
\label{chap3:sec:8:stats}
To compare distributions we first performed normality tests and, when negative, the non parametric test Mann-Whitney U was used for independent samples. For related paired samples we used the Wilcoxon signed-rank test. 
All test were implemented with the Scipy [\url{www.scipy.org}] ecosystem for python. 

The question whether CNO application had an effect on information content in place cells involved comparisons across conditions for different animals and with different numbers of cells for each recording.
The contribution of animal variability could in principle mask the statistical significance of the condition effect, and the difference in counts broke the symmetry needed for some standard statistical tests. 
For these reason, to explore the difference in the information content of cells in both conditions, but excluding the animal variability, we used a Linear Mixed Effects Model (LMEM) with treatment (CNO or Saline injection) as the fixed effect, and animal (or FOV depending on the experimental paradigm) as the random effect. 
LMEM was fitted using the \textit{lme4} and \textit{lmerTest} and \textit{car} libraries from \textbf{R} [\cite{Rsoftware}]. 
We compare two models described as follows:
\begin{align}
    MI & \sim treatment + (1|animal) \label{eqn:LMEM1} \\
    MI & \sim treatment + (1+treatment|animal) \label{eqn:LMEM2}
\end{align}
Equation \ref{eqn:LMEM1} represents a model with one fixed effect and a random intercept for the animal. 
Equation \ref{eqn:LMEM2} adds a random slope to the previous model. 
To compare both models, an ANOVA test was performed. If the more complex model described significantly more variance, then model \ref{eqn:LMEM2} was used.
If, on the other hand, there was no significant difference across models, the simpler one (\ref{eqn:LMEM1}) was preferred. 
After fitting the model, statistical significance of the fixed effect was tested using a Type II Wald chi-square tests implemented as in the \textit{car::Anova} function.


% =========================================================== %
%   Subsection: Decoding of position from neural activity     %
% =========================================================== %
% \section{Decoding of position from neural activity}
% \label{chap3:sec:9:decoders}

% =========================================================== %
%          Subsection: Dimensionality reduction               %
% =========================================================== %
% \section{Dimensionality reduction}
% \label{chap3:sec:10:dim_red}
